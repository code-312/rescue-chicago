{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import (mean_squared_error, mean_absolute_error, r2_score)\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_pickle(\"data/preprocessed_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# high level plot of heatmap\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "corr = df_raw.corr()\n",
    "f, ax = plt.subplots(figsize=(100,100))\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "sns.heatmap(corr,annot = True, mask = mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_correlated(df, threshold):\n",
    "    corr_matrix = df.corr().abs()\n",
    "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "    reduced_corr_matrix = corr_matrix.mask(mask)\n",
    "    features_to_drop = [c for c in reduced_corr_matrix.columns if any(reduced_corr_matrix[c] > threshold)]\n",
    "    return features_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = identify_correlated(df_raw, threshold=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.DataFrame(df_raw.drop(to_drop, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_raw.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to figure out how to pre process these fields\n",
    "df_raw = df_raw.drop(['city', 'state'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_raw[\"los\"]\n",
    "\n",
    "features = []\n",
    "for col in df_raw.columns:\n",
    "    if col != \"los\":  # Skip the 'Target' column if it exists\n",
    "        features.append(col)\n",
    "\n",
    "X = df_raw[features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = identify_correlated(X, threshold=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X.drop(to_drop, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in df_raw.columns:\n",
    "#     print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=312)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set up hyperparameter search space for the random forest regressor\n",
    "# random_grid = {\n",
    "#     \"bootstrap\": [True, False],\n",
    "#     \"max_depth\": [int(x) for x in np.linspace(10, 110, num=11)],\n",
    "#     \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "#     # \"max_leaf_nodes\": None,\n",
    "#     # \"max_samples\": None,\n",
    "#     # \"min_impurity_decrease\": 0.0,\n",
    "#     \"min_samples_leaf\": [1, 2, 4, 8],\n",
    "#     \"min_samples_split\": [2, 4, 8, 16],\n",
    "#     # \"min_weight_fraction_leaf\": 0.0,\n",
    "#     \"n_estimators\": [int(x) for x in np.linspace(start=200, stop=2000, num=10)],\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgbregressor and lgbmregressor, need to change feature names because of symbols\n",
    "\n",
    "models = [SGDRegressor(random_state = 0), \n",
    "          GradientBoostingRegressor(random_state = 0), \n",
    "          LinearRegression(),\n",
    "          DecisionTreeRegressor(),\n",
    "          RandomForestRegressor(random_state = 0)]\n",
    "          #XGBRegressor(),\n",
    "          #LGBMRegressor()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results ={}\n",
    "\n",
    "for model in models:\n",
    "    \n",
    "    # initalize the models\n",
    "    regr = model\n",
    "    regr.fit(X_train, y_train)\n",
    "    \n",
    "    # predictions from models\n",
    "    y_test_pred = regr.predict(X_test)\n",
    "    \n",
    "    # model name and stored results with each model\n",
    "    name = str(model).split(\"(\")[0]\n",
    "    \n",
    "    results[name] = r2_score(y_test, y_test_pred)\n",
    "    print('{} done. R-squared: {:.2f}'.format(name, results[name]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train the regressor\n",
    "# regr = RandomForestRegressor(max_depth=5, random_state=312, criterion=\"mse\")\n",
    "# regr_random = RandomizedSearchCV(estimator=regr, param_distributions=random_grid, n_iter=100, cv=5, random_state=312, n_jobs=-1)\n",
    "\n",
    "# regr_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out selected parameters\n",
    "best_params = regr_random.best_params_\n",
    "\n",
    "print(regr_random.best_score_)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain using the best params\n",
    "regr = RandomForestRegressor(n_jobs=-1, random_state=312).set_params(**best_params)\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# infer on test data\n",
    "yhat = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot inferences\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(yhat, y_test, edgecolors=(0, 0, 1))\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=3)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.Series(regr.feature_importances_, index=regr.feature_names_in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(feature_importances.sort_values(ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate performance\n",
    "mse = mean_squared_error(y_test, yhat)\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "r2 = r2_score(y_test, yhat)\n",
    "\n",
    "metrics_rfr = {\n",
    "    \"mse\": mse,\n",
    "    \"mae\": mae,\n",
    "    \"r2\": r2,\n",
    "}\n",
    "# df_metrics = pd.DataFrame.from_dict(metrics, orient=\"index\", columns=[\"RandomForestRegressor\"])\n",
    "\n",
    "# evaluate a baseline of always guessing the mean\n",
    "yhat = np.ones((y_test.shape[0],1)) * y_train.mean()\n",
    "mse = mean_squared_error(y_test, yhat)\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "r2 = r2_score(y_test, yhat)\n",
    "\n",
    "metrics_baseline = {\n",
    "    \"mse\": mse,\n",
    "    \"mae\": mae,\n",
    "    \"r2\": r2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame.from_dict(data={\"Baseline\": metrics_baseline, \"RandomForestRegressor\": metrics_rfr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up hyperparameter search space for the XGBoost regressor\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 500, 1000],\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.5],\n",
    "    \"subsample\": [0.5, 0.75, 1.0],\n",
    "    \"colsample_bytree\": [0.5, 0.75, 1.0],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "regr = XGBRegressor(random_state=312, objective=\"reg:squarederror\")\n",
    "regr_cv = GridSearchCV(estimator=regr, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "X_train.columns = [col.replace(\"[\", \"_\").replace(\"]\", \"_\") for col in X_train.columns]\n",
    "regr_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out selected parameters\n",
    "best_params = regr_cv.best_params_\n",
    "print(f\"Best score: {regr_cv.best_score_}\")\n",
    "print(f\"Best parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain using the best params\n",
    "regr = XGBRegressor(random_state=312, objective=\"reg:squarederror\").set_params(**best_params)\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer on test data\n",
    "X_test.columns = [col.replace(\"[\", \"_\").replace(\"]\", \"_\") for col in X_test.columns]\n",
    "y_pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print feature importances\n",
    "feature_importances = pd.Series(regr.feature_importances_, index=X_train.columns)\n",
    "print(\"Top 20 most important features:\")\n",
    "print(feature_importances.sort_values(ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "metrics_xgb = {\"mse\": mse, \"mae\": mae, \"r2\": r2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate a baseline of always guessing the mean\n",
    "y_mean = y_train.mean()\n",
    "y_pred_baseline = np.full(y_test.shape, y_mean)\n",
    "mse_baseline = mean_squared_error(y_test, y_pred_baseline)\n",
    "mae_baseline = mean_absolute_error(y_test, y_pred_baseline)\n",
    "r2_baseline = r2_score(y_test, y_pred_baseline)\n",
    "\n",
    "metrics_baseline = {\"mse\": mse_baseline, \"mae\": mae_baseline, \"r2\": r2_baseline}\n",
    "\n",
    "df_metrics = pd.DataFrame.from_dict(\n",
    "    {\"Baseline\": metrics_baseline, \"XGBRegressor\": metrics_xgb}\n",
    ")\n",
    "print(df_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "a4b8b30545f5d65175c89d8b33afca65e1f9aa03e972311ddac705e77798068f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
