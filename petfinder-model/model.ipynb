{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import category_encoders as ce\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from config import AGE_DICT, SIZE_DICT, TARGET_COLS, BINARY_COLS\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Data preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Clustering Models\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score, accuracy_score, classification_report, confusion_matrix, roc_curve, roc_auc_score, auc\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Classification models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEROKU_URL = os.getenv('HEROKU_POSTGRESQL_AMBER_URL')\n",
    "\n",
    "uri = HEROKU_URL \n",
    "if uri.startswith(\"postgres://\"):\n",
    "    uri = uri.replace(\"postgres://\", \"postgresql://\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading data\n",
    "def read_data():\n",
    "    df_raw = df_raw = pd.read_sql('petfinder_with_dates', uri)  \n",
    "    return df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "\n",
    "    # dropping irrelevant columns\n",
    "    df = df.drop(columns=[\"id\", \"name\", \"organization_id\", \"published_at\", \"status_changed_at\", \"attribute_declawed\", \"color_tertiary\", \"good_with_cats\", \"good_with_children\", \"good_with_dogs\", \"breed_secondary\", \"color_secondary\"])\n",
    "\n",
    "    # transform \"age\" column \n",
    "    df['age'] = df['age'].map(AGE_DICT).astype(str).astype(int)\n",
    "\n",
    "    # transform \"size\" column\n",
    "    df['size'] = df['size'].map(SIZE_DICT).astype(str).astype(int)\n",
    "\n",
    "    # dropping unknown values in gender\n",
    "    df.drop(df[df['gender'] == 'Unknown'].index, inplace=True)\n",
    "\n",
    "    # Convert binary columns to binary (0/1) data type\n",
    "    df[BINARY_COLS] = df[BINARY_COLS].astype(bool).astype(int)\n",
    "\n",
    "    # # Replace 'Male' and 'Female' with 0 and 1, respectively\n",
    "\n",
    "    # # Replace 'Male' and 'Female' with 0 and 1, respectively, and convert to int\n",
    "    # df['gender'] = df['gender'].replace({\"Male\": 0, \"Female\": 1}).astype(int)\n",
    "\n",
    "    # Filter data for los 1+\n",
    "    df = df[df['los'] >= 1]\n",
    "\n",
    "    # target encoding on larger categorical features\n",
    "    te = ce.TargetEncoder(cols=TARGET_COLS)\n",
    "    df[TARGET_COLS] = te.fit_transform(df[TARGET_COLS], df[\"los\"])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nan_mode(df, reference_column, feature):\n",
    "    # Calculate the mode coat for each breed_primary\n",
    "    mode_by_breed = df.groupby(reference_column)[feature].apply(lambda x: x.mode().iloc[0] if not x.isnull().all() else None)\n",
    "\n",
    "    # Create a dictionary mapping each breed to its mode coat\n",
    "    mode_dict = dict(mode_by_breed)\n",
    "\n",
    "    # Fill the NaN values in 'coat' based on the breed using the mode_dict\n",
    "    df[feature] = df.apply(lambda row: mode_dict[row[reference_column]] if pd.isna(row[feature]) and row[reference_column] in mode_dict else row[feature], axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows with null coat and color primary\n",
    "def drop_null_rows(df, feature):\n",
    "    df.dropna(subset=[feature], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers\n",
    "def remove_outliers(df, columns, zscore_threshold=3):\n",
    "    for col in columns:\n",
    "        mean = df[col].mean()\n",
    "        std = df[col].std()\n",
    "        z_scores = np.abs((df[col] - mean) / std)\n",
    "        df = df[z_scores <= zscore_threshold]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split data into training and testing data\n",
    "# def split_data(X, y, test_size = .33, random_state=312):\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "#     return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform Randomized Search\n",
    "# def perform_randomized_search(model, param_distributions, X_train, y_train, scoring='r2', cv=5):\n",
    "#     random_search = RandomizedSearchCV(model, param_distributions=param_distributions, scoring=scoring, cv=cv, n_jobs=-1, random_state=0)\n",
    "#     random_search.fit(X_train, y_train)\n",
    "#     # best_model = random_search.best_estimator_\n",
    "    \n",
    "#     return random_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train and eval models\n",
    "\n",
    "# def train_eval_models(X_train, X_test, y_train, y_test, model):\n",
    "#     # Create a pipeline to scale the features and initialize the model\n",
    "#     pipeline = Pipeline([\n",
    "#         ('scaler', StandardScaler()),\n",
    "#         ('model', model)\n",
    "#     ])\n",
    "\n",
    "#     # Perform cross-validation with additional metrics\n",
    "#     scores_r2 = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='r2')\n",
    "#     scores_mae = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "#     scores_mse = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "#     mean_score_r2 = scores_r2.mean()\n",
    "#     mean_score_mae = -scores_mae.mean()\n",
    "#     mean_score_mse = -scores_mse.mean()\n",
    "\n",
    "#     # Model name and store results with each model\n",
    "#     name = model.__class__.__name__\n",
    "#     print('{} done. Mean R-squared (CV): {:.2f}, Mean MAE (CV): {:.2f}, Mean MSE (CV): {:.2f}'.format(\n",
    "#         name, mean_score_r2, mean_score_mae, mean_score_mse))\n",
    "\n",
    "#     # Train the best model on the entire training set and evaluate on the test set\n",
    "#     pipeline.fit(X_train, y_train)\n",
    "#     y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "#     print('R-squared (test set): {:.2f}'.format(r2_score(y_test, y_test_pred)))\n",
    "#     print('Mean squared error (test set): {:.2f}'.format(mean_squared_error(y_test, y_test_pred)))\n",
    "#     print('Mean absolute error (test set): {:.2f}'.format(mean_absolute_error(y_test, y_test_pred)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from the database\n",
    "df_raw = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "df_preprocessed = preprocess_data(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "outlier_columns = ['organization_name', 'los', 'breed_primary']\n",
    "df_no_outliers = remove_outliers(df_preprocessed, outlier_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fill_nan_mode(df_no_outliers, 'breed_primary', 'coat')\n",
    "df = fill_nan_mode(df_no_outliers, 'breed_primary', 'color_primary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = drop_null_rows(df, 'coat')\n",
    "df = drop_null_rows(df, 'color_primary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split data into training and testing sets\n",
    "# X = df.drop('los', axis = 1)\n",
    "# y = df['los']\n",
    "# X_train, X_test, y_train, y_test = split_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_params = {\n",
    "#     RandomForestRegressor: {'n_estimators': [10, 50, 100, 200], 'max_depth': [None, 10, 20, 30], 'random_state': [0]},\n",
    "#     GradientBoostingRegressor: {'n_estimators': [10, 50, 100, 200], 'learning_rate': [0.01, 0.1, 1.0], 'random_state': [0]},\n",
    "#     XGBRegressor: {'n_estimators': [10, 50, 100, 200], 'learning_rate': [0.01, 0.1, 1.0], 'random_state': [0]},\n",
    "#     LGBMRegressor: {'n_estimators': [10, 50, 100, 200], 'learning_rate': [0.01, 0.1, 1.0]}\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # saves the best estimator found by randomized search for each model with key being the model name\n",
    "# best_models = {}\n",
    "# for model, params in models_params.items():\n",
    "#     randomized_search = perform_randomized_search(model(), params, X_train, y_train)\n",
    "#     best_model = randomized_search.best_estimator_\n",
    "#     best_models[model.__name__] = best_model\n",
    "#     train_eval_models(X_train, X_test, y_train, y_test, best_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform Stacking: defining the estimators it pulls models from the best_models dictionary\n",
    "# estimators = [\n",
    "#     ('ridge', Ridge()),\n",
    "#     ('rf', best_models['RandomForestRegressor']),\n",
    "#     ('gb', best_models['GradientBoostingRegressor']),\n",
    "#     ('xgb', best_models['XGBRegressor']),\n",
    "#     ('lgbm', best_models['LGBMRegressor'])\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ridge is used to help with overfitting\n",
    "# final_model = StackingRegressor(estimators=estimators, final_estimator=Ridge(), cv=5)\n",
    "# _ = train_eval_models(X_train, X_test, y_train, y_test, final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model training and validation on entire dataset\n",
    "# final_model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale data using Standard Scaler for better clustering results\n",
    "scaler = StandardScaler()\n",
    "full_data = scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list to store the sum of squared distances for each k\n",
    "ssd = []\n",
    "\n",
    "# fit KMeans clustering with different values of k\n",
    "for k in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(full_data)\n",
    "    ssd.append(kmeans.inertia_)\n",
    "\n",
    "# create a dataframe with the k values and corresponding ssd\n",
    "df_ssd = pd.DataFrame({'k': range(1, 11), 'ssd': ssd})\n",
    "\n",
    "# create the line plot using matplotlib\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_ssd['k'], df_ssd['ssd'], marker='o')\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Sum of Squared Distances')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fit PCA without limiting the number of components to see all explained variances\n",
    "pca = PCA()\n",
    "pca.fit(full_data)\n",
    "\n",
    "# Plotting the explained variance\n",
    "explained_var = pca.explained_variance_ratio_.cumsum()\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1, len(explained_var)+1), explained_var, marker='o', linestyle='--')\n",
    "plt.title(\"Cumulative Explained Variance\")\n",
    "plt.xlabel(\"Number of Components\")\n",
    "plt.ylabel(\"Cumulative Explained Variance Ratio\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=14, random_state=42)\n",
    "df_pca = pca.fit_transform(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=6, random_state=42)\n",
    "kmeans.fit(df_pca)\n",
    "pred = kmeans.predict(df_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of unique clusters\n",
    "unique_clusters = np.unique(pred)\n",
    "\n",
    "# Generate a colormap and pick colors for each cluster\n",
    "colors = plt.cm.jet(np.linspace(0, 1, len(unique_clusters)))\n",
    "\n",
    "for i, color in enumerate(colors):\n",
    "    plt.scatter(df_pca[pred == i, 0], df_pca[pred == i, 1], s=50, c=[color], label=f'Cluster {i+1}')\n",
    "    \n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=200, marker='+', c='black', label='Centers')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append cluster assignments to the dataframe\n",
    "df['Cluster'] = pred\n",
    "\n",
    "# Calculate mean values for each feature by cluster\n",
    "cluster_means = df.groupby('Cluster').mean()\n",
    "cluster_medians = df.groupby('Cluster').median()\n",
    "\n",
    "print(cluster_means)\n",
    "print(cluster_medians)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and target\n",
    "X = df.drop('Cluster', axis=1) \n",
    "y = df['Cluster']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_petfinder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
